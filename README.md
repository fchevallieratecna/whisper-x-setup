# ğŸ¤ Modern Whisper Setup (September 2025)

**Transcription et diarization avancÃ©es avec les derniÃ¨res technologies 2025**

[![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)](https://github.com/fchevallieratecna/whisper-x-setup)
[![Python](https://img.shields.io/badge/python-3.9--3.12-brightgreen.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/pytorch-2.7.1-red.svg)](https://pytorch.org)
[![CUDA](https://img.shields.io/badge/cuda-12.8-green.svg)](https://developer.nvidia.com/cuda-toolkit)

## ğŸ†• NouveautÃ©s 2025

- **ğŸš€ Passage Ã  `faster-whisper`** : Performances 70x plus rapides que WhisperX
- **ğŸ§  NeMo 2.0** : Diarization de pointe avec NVIDIA NeMo
- **âš¡ PyTorch 2.7.1** : Support CUDA 12.8 optimisÃ©
- **ğŸ¯ CLI moderne** : Interface utilisateur repensÃ©e
- **ğŸ“Š Community-1** : ModÃ¨le de diarization pyannote le plus rÃ©cent
- **ğŸ Python 3.9-3.12** : CompatibilitÃ© Ã©tendue

## ğŸ“‹ PrÃ©-requis

### SystÃ¨me
- **Ubuntu 20.04+** ou **macOS 12+**
- **Python 3.9-3.12**
- **Git** et **FFmpeg**
- **16GB RAM** recommandÃ©s (8GB minimum)

### GPU (Optionnel mais recommandÃ©)
- **NVIDIA GPU** avec **8GB+ VRAM**
- **CUDA 11.0+** (12.8 optimal)
- **Driver NVIDIA** rÃ©cent

## ğŸš€ Installation Rapide

### Installation ComplÃ¨te (RecommandÃ©e)

```bash
# Cloner le projet
git clone https://github.com/fchevallieratecna/whisper-x-setup.git
cd whisper-x-setup

# Lancer l'installation moderne
chmod +x setup_modern.sh
./setup_modern.sh --verbose --hf-token=YOUR_HF_TOKEN
```

### Options d'installation

```bash
# Installation avec options avancÃ©es
./setup_modern.sh \
  --verbose \
  --hf-token=hf_xxxxxxxxxxxx \
  --ngrok-token=xxxxxxxxxxxx \
  --use-conda

# Installation API uniquement
./setup_modern.sh --only-api --ngrok-token=xxxxxxxxxxxx

# Installation sans NeMo (plus rapide)
./setup_modern.sh --no-nemo --hf-token=hf_xxxxxxxxxxxx
```

## ğŸ“± Utilisation du CLI

### Commandes de base

```bash
# Transcription simple
whisper_modern_cli audio.mp3 --model large-v3 --language fr

# Avec diarization (identification des locuteurs)
whisper_modern_cli meeting.wav \
  --diarize \
  --hf_token YOUR_TOKEN \
  --nb_speaker 3 \
  --output_format srt

# Sur macOS (CPU optimisÃ©)
whisper_modern_cli audio.mp3 \
  --compute_type int8 \
  --device cpu \
  --model large-v3
```

### Options avancÃ©es

```bash
# Diarization avec NeMo (plus prÃ©cis)
whisper_modern_cli interview.mp3 \
  --diarize \
  --diarization_backend nemo \
  --model large-v3 \
  --language fr

# Traitement par batch optimisÃ©
whisper_modern_cli long_audio.wav \
  --batch_size 16 \
  --compute_type float16 \
  --initial_prompt "Cette rÃ©union concerne..."

# Debug et dÃ©veloppement
whisper_modern_cli test.mp3 \
  --debug \
  --model base \
  --output debug_output.json \
  --output_format json
```

## ğŸ¯ Formats de sortie

### TXT (DÃ©faut)
```
[SPEAKER_00] Bonjour et bienvenue dans cette rÃ©union.
[SPEAKER_01] Merci, je suis ravi d'Ãªtre ici.
[SPEAKER_00] CommenÃ§ons par le premier point de l'ordre du jour.
```

### SRT (Sous-titres)
```
1
00:00:00,000 --> 00:00:03,500
[SPEAKER_00] Bonjour et bienvenue dans cette rÃ©union.

2
00:00:03,500 --> 00:00:06,200
[SPEAKER_01] Merci, je suis ravi d'Ãªtre ici.
```

### JSON (DÃ©taillÃ©)
```json
{
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": "Bonjour et bienvenue dans cette rÃ©union.",
      "speaker": "SPEAKER_00",
      "confidence": 0.98
    }
  ],
  "language": "fr",
  "duration": 1800.5
}
```

## ğŸ”§ Configuration AvancÃ©e

### Variables d'environnement

```bash
# Token Hugging Face
export HF_TOKEN="hf_xxxxxxxxxxxxxxxxxxxx"

# Configuration GPU
export CUDA_VISIBLE_DEVICES="0"

# Optimisation mÃ©moire
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512"
```

### Fichier de configuration (optionnel)

CrÃ©ez `config.yaml` :

```yaml
model:
  size: "large-v3"
  language: "fr"
  compute_type: "float16"

diarization:
  enabled: true
  backend: "pyannote"  # ou "nemo"
  min_speakers: 1
  max_speakers: 10

output:
  format: "srt"
  include_timestamps: true
  include_confidence: true

processing:
  batch_size: 8
  use_vad: true
  beam_size: 5
```

## ğŸ“Š Comparaison des Performances

| MÃ©thode | Vitesse | PrÃ©cision | Diarization | VRAM |
|---------|---------|-----------|-------------|------|
| OpenAI Whisper | 1x | â­â­â­â­ | âŒ | 6GB |
| WhisperX | 70x | â­â­â­â­ | â­â­â­ | 8GB |
| **Modern Setup** | **70x** | **â­â­â­â­â­** | **â­â­â­â­â­** | **6GB** |

## ğŸ” DÃ©pannage

### Erreurs communes

```bash
# Erreur de mÃ©moire GPU
whisper_modern_cli audio.mp3 --compute_type int8 --batch_size 4

# ProblÃ¨me de token Hugging Face
whisper_modern_cli audio.mp3 --no-diarize

# Erreur macOS
whisper_modern_cli audio.mp3 --device cpu --compute_type int8
```

### VÃ©rification de l'installation

```bash
# Version et informations
whisper_modern_cli --version

# Test rapide
whisper_modern_cli test_audio.wav --model base --debug
```

## ğŸŒ API REST

L'installation inclut Ã©galement une API REST moderne :

```bash
# DÃ©marrer l'API
pm2 start whisper-api-modern

# Test de l'API
curl -X POST "http://localhost:3000/api/transcribe" \
  -F "file=@audio.mp3" \
  -F "model=large-v3" \
  -F "language=fr" \
  -F "diarize=true"
```

### Endpoints disponibles

- `POST /api/transcribe` - Transcription avec diarization
- `GET /api/models` - Liste des modÃ¨les disponibles
- `GET /api/status` - Statut du service
- `GET /api/health` - Health check

## ğŸ”„ Migration depuis WhisperX

### Commandes Ã©quivalentes

```bash
# Ancienne commande WhisperX
whisperx audio.mp3 --model large-v2 --diarize --language fr

# Nouvelle commande (Modern Setup)
whisper_modern_cli audio.mp3 --model large-v3 --diarize --language fr
```

### Avantages de la migration

- **Performance** : 2-3x plus rapide
- **PrÃ©cision** : Meilleure diarization avec Community-1
- **StabilitÃ©** : Moins de bugs et dÃ©pendances
- **Support** : Projet activement maintenu

## ğŸ“š Documentation Technique

### Architecture

```
Modern Whisper Setup
â”œâ”€â”€ faster-whisper (ASR core)
â”œâ”€â”€ pyannote.audio (Diarization)
â”œâ”€â”€ NeMo 2.0 (Advanced diarization)
â”œâ”€â”€ PyTorch 2.7.1 (Backend)
â””â”€â”€ Custom CLI (Interface)
```

### ModÃ¨les supportÃ©s

| ModÃ¨le | Taille | VRAM | Langue | Vitesse |
|--------|--------|------|--------|---------|
| tiny | 39MB | 1GB | Multilingue | TrÃ¨s rapide |
| base | 74MB | 1GB | Multilingue | Rapide |
| small | 244MB | 2GB | Multilingue | Moyen |
| medium | 769MB | 5GB | Multilingue | Lent |
| large-v3 | 1550MB | 10GB | Multilingue | TrÃ¨s lent |

## ğŸ¤ Contribution

### DÃ©veloppement local

```bash
# Installation en mode dÃ©veloppement
git clone https://github.com/fchevallieratecna/whisper-x-setup.git
cd whisper-x-setup

# Installation des dÃ©pendances de dÃ©veloppement
pip install -r requirements_modern.txt
pip install -e .

# Tests
python -m pytest tests/
```

### Signaler un bug

1. VÃ©rifiez les [issues existantes](https://github.com/fchevallieratecna/whisper-x-setup/issues)
2. CrÃ©ez une nouvelle issue avec :
   - Version du systÃ¨me
   - Commande utilisÃ©e
   - Logs d'erreur complets
   - Fichier audio de test (si possible)

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™ Remerciements

- [OpenAI](https://openai.com/) pour Whisper
- [SYSTRAN](https://github.com/SYSTRAN/faster-whisper) pour faster-whisper
- [pyannote](https://github.com/pyannote/pyannote-audio) pour la diarization
- [NVIDIA](https://github.com/NVIDIA/NeMo) pour NeMo
- [MahmoudAshraf97](https://github.com/MahmoudAshraf97/whisper-diarization) pour l'inspiration

## ğŸ“ Support

- ğŸ“§ Email : support@whisper-modern.com
- ğŸ’¬ Discord : [CommunautÃ© Whisper FR](https://discord.gg/whisper-fr)
- ğŸ“– Wiki : [Documentation complÃ¨te](https://github.com/fchevallieratecna/whisper-x-setup/wiki)

---

**Fait avec â¤ï¸ pour la communautÃ© franÃ§aise de l'IA**